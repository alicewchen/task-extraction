{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alice/git-repo/task-extraction\n",
      "/home/alice/git-repo/task-extraction/scripts\n",
      "['', '/home/alice/git-repo/task-extraction', '/usr/lib/python3.10', '/home/alice/git-repo/task-extraction/src', '/home/alice/git-repo/task-extraction/venv/lib/python3.10/site-packages', '/usr/lib/python310.zip', '/usr/lib/python3.10/lib-dynload']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "notebook_path = os.getcwd()  # Get the current working directory\n",
    "project_root = os.path.dirname(notebook_path)  # Get the parent directory\n",
    "print(project_root)\n",
    "print(notebook_path)\n",
    "sys.path.append(project_root)\n",
    "os.chdir(project_root)\n",
    "sys.path.append(project_root + '/src')\n",
    "sys.path = list(set(sys.path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4e-05\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from src.lb_annotation_utils import Article\n",
    "from src.llm_utils import system_prompts, estimate_token_cost\n",
    "import re\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=os.getenv(\"OPENROUTER_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "MAP_FOLDER = \"data/neurovault_labeled_papers/\"\n",
    "INDEX_FILE = MAP_FOLDER + \"nv_labeled_tasks_pmcid_map.json\"\n",
    "TASK_FILE_PATTERN = MAP_FOLDER + \"nv_labeled_tasks_{chunk_number}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = json.load(open('data/labelbuddy_annotations/nv_collection/annotations.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No subheaders found in body section\n"
     ]
    }
   ],
   "source": [
    "# Set up filter logic\n",
    "# exclusion criteria\n",
    "exclude_types = [\"resting_state\", \"meta-analysis\"]\n",
    "# excluded articles\n",
    "excluded_articles = []\n",
    "# included articles\n",
    "included_articles = []  \n",
    "# extract methods\n",
    "for i in range(len(ann)):\n",
    "    article_obj  = Article(ann[i])\n",
    "    if article_obj.type in exclude_types:\n",
    "        excluded_articles.append({\"pmcid\": article_obj.pmcid, \"exclusion_reason\":{\"type\": article_obj.type}})\n",
    "    elif article_obj.methods == \"No explicit methods section\":\n",
    "        excluded_articles.append({\"pmcid\": article_obj.pmcid, \"exclusion_reason\":{\"methods\": \"No explicit methods section\"}})\n",
    "    else:\n",
    "        included_articles.append(article_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pmcid': 5324609,\n",
       "  'exclusion_reason': {'methods': 'No explicit methods section'}},\n",
       " {'pmcid': 5090046, 'exclusion_reason': {'type': 'resting_state'}},\n",
       " {'pmcid': 10634720, 'exclusion_reason': {'type': 'meta-analysis'}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excluded_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<src.lb_annotation_utils.Article at 0x7f84a118d990>,\n",
       " <src.lb_annotation_utils.Article at 0x7f84a2d92590>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "included_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0024749999999999998\n"
     ]
    }
   ],
   "source": [
    "total_cost = 0\n",
    "for i in range(len(included_articles)):\n",
    "    article_obj  = included_articles[i]\n",
    "    if article_obj.methods!=\"No explicit methods section\":\n",
    "        item = {\"pmcid\": article_obj.pmcid, \"methods\": article_obj.methods}\n",
    "        total_cost += estimate_token_cost(article_obj.methods, \"text-embedding-3-small\")\n",
    "    else:\n",
    "        item = {\"pmcid\": article_obj.pmcid, \"methods\": None}\n",
    "print(total_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_using_llm(text:str, client:OpenAI, call_message:callable):\n",
    "    messages = call_message(text)\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'openai/gpt-4o-mini',\n",
    "        messages = messages,\n",
    "        seed = 42, \n",
    "        response_format = {\"type\": \"json_object\"}\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "def extract_cognitive_task(text:str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompts['CognitiveTask']}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{text}\"},\n",
    "]\n",
    "    return messages\n",
    "def extract_cognitive_task_description(text:str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompts['CognitiveTaskDescription']}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{text}\"},\n",
    "]   \n",
    "    return messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(included_articles)):\n",
    "    methods = included_articles[i].methods\n",
    "    output = extract_using_llm(text = methods, client = client, call_message = extract_cognitive_task)\n",
    "    if re.search(r'null', output):\n",
    "        output_description = extract_using_llm(text = methods, client = client, call_message = extract_cognitive_task_description)\n",
    "        included_articles[i].llm.cognitive_task_description = output_description\n",
    "    else:\n",
    "        included_articles[i].llm.cognitive_task = output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8318202\n",
      "{\"cognitive_task\": [\"attentive listening\", \"word repetition\"]}\n",
      "None\n",
      "\n",
      "\n",
      "9202476\n",
      "{\"cognitive_task\": [\"match-to-sample (MTS) task\", \"visual search\", \"visual attention\", \"reaction time measurement\"]}\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(included_articles)):\n",
    "    print(included_articles[i].pmcid)\n",
    "    print(included_articles[i].llm.cognitive_task)\n",
    "    print(included_articles[i].llm.cognitive_task_description)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35720693\n",
      "10.3389/fnins.2022.850372\n",
      "['35720693', ['data/neurovault_labeled_papers/nv_labeled_tasks_0.json']]\n",
      "{'cognitive_task': '{\"cognitive_task\": [\"attentive listening\", \"word repetition\"]}', 'cognitive_task_description': None}\n",
      "[{'35720693': {'pmcid': '35720693', 'task': {'id': 'trm_4c8a834779883', 'name': 'rest eyes open', 'definition_text': 'Subjects rest passively with their eyes open. Often used as a baseline for comparison for other tasks.'}, 'pmid': '35720693', 'doi': '10.3389/fnins.2022.850372'}}]\n",
      "['34327333', ['data/neurovault_labeled_papers/nv_labeled_tasks_5.json']]\n",
      "{'cognitive_task': '{\"cognitive_task\": [\"attentive listening\", \"word repetition\"]}', 'cognitive_task_description': None}\n",
      "[{'34327333': {'pmcid': '34327333', 'task': {'id': 'trm_550b54a8b30f4', 'name': 'language processing fMRI task paradigm', 'definition_text': 'This task was developed by Binder and colleagues (Binder et al. 2011) and uses the E-prime scripts provided by these investigators. The task consists of two runs that each interleave 4 blocks of a story task and 4 blocks of a math task. The lengths of the blocks vary (average of approximately 30 seconds), but the task was designed so that the math task blocks match the length of the story task blocks, with some additional math trials at the end of the task to complete the 3.8 minute run as needed. The story blocks present participants with brief auditory stories (5-9 sentences) adapted from Aesopâ\\x80\\x99s fables, followed by a 2-alternative forcedchoice question that asks participants about the topic of the story. The example provided in the original Binder paper (p. 1466) is â\\x80\\x9cFor example, after a story about an eagle that saves a man who had done him a favor, participants were asked, â\\x80\\x9cWas that about revenge or reciprocity?â\\x80\\x9d The math task also presents trials aurally and requires subjects to complete addition and subtraction problems. The trials present subjects with a series of arithmetic operations (e.g., â\\x80\\x9cfourteen plus twelveâ\\x80\\x9d), followed by â\\x80\\x9cequalsâ\\x80\\x9d and then two choices (e.g., â\\x80\\x9ctwenty-nine or twentysixâ\\x80\\x9d). Participants push a button to select either the first or the second answer. The math task is adaptive to try to maintain a similar level of difficulty across participants. For more details on the task, please see (Binder et al. 2011).\\r\\n\\r\\nReferences for Language Task: Reliable across subjects and robust activation (Binder et al.\\r\\n2011).\\r\\n\\r\\nThis task is included in the Human Connectome Project.\\r\\n\\r\\nhttp://humanconnectome.org/documentation/S500/HCP_S500+MEG2_Release_Reference_Manual.pdf'}, 'pmid': '34327333', 'doi': '10.1162/nol_a_00021'}}]\n"
     ]
    }
   ],
   "source": [
    "def get_nv_labeled_tasks(pmcid, index_file = INDEX_FILE,json_file_pattern = TASK_FILE_PATTERN):\n",
    "    nv_labeled_tasks = []\n",
    "    query_pmcid = str(pmcid)\n",
    "    with open(index_file, \"r\") as f:\n",
    "        indexer = json.load(f)\n",
    "        task_location = indexer[query_pmcid]\n",
    "        print([query_pmcid, task_location])\n",
    "        for file in task_location:\n",
    "            with open(file, \"r\") as ff:\n",
    "                extracted_tasks = json.load(ff)\n",
    "                for task in extracted_tasks:\n",
    "                    if list(task.keys())[0] == query_pmcid:\n",
    "                        nv_labeled_tasks.append(task)\n",
    "    return nv_labeled_tasks\n",
    "# Table\n",
    "\n",
    "print(included_articles[1].pmid)\n",
    "print(included_articles[1].doi)\n",
    "nv_labeled_tasks = get_nv_labeled_tasks(pmcid = included_articles[1].pmid)\n",
    "print(included_articles[0].llm.__dict__)\n",
    "print(nv_labeled_tasks)\n",
    "\n",
    "nv_labeled_tasks = get_nv_labeled_tasks(pmcid = included_articles[0].pmid)\n",
    "print(included_articles[0].llm.__dict__)\n",
    "print(nv_labeled_tasks)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from src.data_utils import calculate_bert_score\n",
    "calculator = BERTScoreCalculator()\n",
    "\n",
    "calculator.calculate_bert_score(included_articles[0].cognitive_task, included_articles[1].cognitive_task)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
